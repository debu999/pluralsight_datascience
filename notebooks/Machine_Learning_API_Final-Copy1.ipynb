{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\src\\models\\machine_learning_api.py\n",
      "D:\\ML\\DATA_SCIENCE\\titanic\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "ml_script_fl = os.path.join(os.pardir, \"src\", \"models\", \"machine_learning_api.py\")\n",
    "print(ml_script_fl)\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "%%writefile $ml_script_fl\n",
    "\n",
    "from flask import Flask, request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, json, pickle\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\"\"\"Load Model and Scalar files\"\"\"\n",
    "model_file_path = os.path.join(os.path.pardir, os.path.pardir, 'models', 'lr_model.pkl')\n",
    "scalar_file_path = os.path.join(os.path.pardir, os.path.pardir, 'models', 'lr_scalar.pkl')\n",
    "mdl_fl_pkl = open(model_file_path,\"rb\")\n",
    "scl_fl_pkl = open(scalar_file_path,\"rb\")\n",
    "\n",
    "model = pickle.load(mdl_fl_pkl)\n",
    "scalar = pickle.load(scl_fl_pkl)\n",
    "\n",
    "columns = [u'Age', u'Fare', u'FamilySize', u'IsMother', u'IsMale',\n",
    "           u'Deck_A', u'Deck_B', u'Deck_C', u'Deck_D', u'Deck_E',\n",
    "           u'Deck_F', u'Deck_G', u'Deck_Z', u'Pclass_1', u'Pclass_2',\n",
    "           u'Pclass_3', u'Title_Lady', u'Title_Master', u'Title_Miss',\n",
    "           u'Title_Mr', u'Title_Mrs', u'Title_Officer', u'Title_Sir',\n",
    "           u'Fare_Bin_very_low', u'Fare_Bin_low', u'Fare_Bin_medium',\n",
    "           u'Fare_Bin_high', u'Embarked_C', u'Embarked_Q', u'Embarked_S',\n",
    "           u'Agestate_Adults', u'Agestate_Child']\n",
    "\n",
    "@app.route('/api', methods=['POST'])\n",
    "def make_predictions():\n",
    "    data = json.dumps(request.get_json(force=True))\n",
    "    df = pd.read_json(data)\n",
    "    passenger_ids = df.PassengerId.ravel()\n",
    "    survivals = df.Survived.ravel()\n",
    "    X = df[columns].as_matrix().astype('float')\n",
    "    Xsc = scalar.transform(X)\n",
    "    p = model.predict(Xsc)\n",
    "    df_response = pd.DataFrame({\"PassengerId\":passenger_ids, \"Predicted\":p, \"Actuals\":survivals})\n",
    "    return df_response.to_json()\n",
    "    \n",
    "    name = data['name']\n",
    "    return \"Hello to API World : {0}\".format(name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(port=8293, debug=True)\n",
    "\n",
    "\n",
    "import json, requests\n",
    "url = \"http://127.0.0.1:8292/api\"\n",
    "data = json.dumps({\"name\":\"Debabrata\"})\n",
    "r = requests.post(url,data)\n",
    "r.text\n",
    "\n",
    "! ls -lrt ..\\src\\models\\\n",
    "\n",
    "### API Invocation \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "processed_data_path = os.path.join(os.path.pardir, \"data\", \"processed\")\n",
    "tr_fl_pt = os.path.join(processed_data_path, \"train.csv\")\n",
    "train_df = pd.read_csv(tr_fl_pt)\n",
    "sur_pass = train_df[train_df['Survived']==1][:10]\n",
    "\n",
    "\n",
    "\n",
    "sur_pass\n",
    "\n",
    "import requests\n",
    "def make_api_request(data):\n",
    "    url = \"http://127.0.0.1:8293/api\"\n",
    "    r = requests.post(url,data)\n",
    "    print(r.status_code)\n",
    "    return r.json()\n",
    "\n",
    "from pprint import pprint as pp\n",
    "pp(make_api_request(sur_pass.to_json()))\n",
    "\n",
    "res = make_api_request(train_df.to_json())\n",
    "df_res = pd.read_json(json.dumps(res))\n",
    "df_res.head()\n",
    "\n",
    "import numpy as np\n",
    "np.mean(df_res.Actuals == df_res.Predicted)\n",
    "\n",
    "from flask import Flask, request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, json, pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\"\"\"Load Model and Scalar files\"\"\"\n",
    "model_file_path = os.path.join( os.path.pardir, 'models', 'lr_model.pkl')\n",
    "scalar_file_path = os.path.join( os.path.pardir, 'models', 'lr_scalar.pkl')\n",
    "mdl_fl_pkl = open(model_file_path,\"rb\")\n",
    "scl_fl_pkl = open(scalar_file_path,\"rb\")\n",
    "\n",
    "model = pickle.load(mdl_fl_pkl)\n",
    "scalar = pickle.load(scl_fl_pkl)\n",
    "\n",
    "columns = [u'Age', u'Fare', u'FamilySize', u'IsMother', u'IsMale',\n",
    "           u'Deck_A', u'Deck_B', u'Deck_C', u'Deck_D', u'Deck_E',\n",
    "           u'Deck_F', u'Deck_G', u'Deck_Z', u'Pclass_1', u'Pclass_2',\n",
    "           u'Pclass_3', u'Title_Lady', u'Title_Master', u'Title_Miss',\n",
    "           u'Title_Mr', u'Title_Mrs', u'Title_Officer', u'Title_Sir',\n",
    "           u'Fare_Bin_very_low', u'Fare_Bin_low', u'Fare_Bin_medium',\n",
    "           u'Fare_Bin_high', u'Embarked_C', u'Embarked_Q', u'Embarked_S',\n",
    "           u'Agestate_Adults', u'Agestate_Child']\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "processed_data_path = os.path.join(os.path.pardir, \"data\", \"processed\")\n",
    "tr_fl_pt = os.path.join(processed_data_path, \"train.csv\")\n",
    "train_df = pd.read_csv(tr_fl_pt)\n",
    "sur_pass = train_df[train_df['Survived']==1][:10]\n",
    "y=train_df['Survived']\n",
    "X = train_df[columns].as_matrix().astype('float')\n",
    "Xsc = scalar.transform(X)\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "processed_data_path = os.path.join(os.path.pardir, \"data\", \"processed\")\n",
    "tr_fl_pt = os.path.join(processed_data_path, \"train.csv\")\n",
    "train_df = pd.read_csv(tr_fl_pt)\n",
    "sur_pass = train_df[train_df['Survived']==1][:10]\n",
    "y=train_df['Survived']\n",
    "X = train_df[columns].as_matrix().astype('float')\n",
    "Xsc = scalar.transform(X)\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "nn = MLPClassifier(activation='logistic', solver='sgd', hidden_layer_sizes=(100,50),random_state=1)\n",
    "nn.fit(Xtrain, ytrain)\n",
    "pred=nn.predict(Xtest)\n",
    "z=pd.DataFrame(pred)\n",
    "e=pd.concat([z,ytest],axis=1)\n",
    "e.head()\n",
    "\n",
    "def make_predictions():\n",
    "    data = train_df.to_json()\n",
    "    df = pd.read_json(data)\n",
    "    passenger_ids = df.PassengerId.ravel()\n",
    "    survivals = df.Survived.ravel()\n",
    "    X = df[columns].as_matrix().astype('float')\n",
    "    Xsc = scalar.transform(X)\n",
    "    p = model.predict(Xsc)\n",
    "    df_response = pd.DataFrame({\"PassengerId\":passenger_ids, \"Predicted\":p, \"Actuals\":survivals})\n",
    "    return df_response\n",
    "\n",
    "\n",
    "\n",
    "x=make_predictions()\n",
    "x[[\"Actuals\",\"Predicted\",\"PassengerId\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
