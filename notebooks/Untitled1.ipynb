{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = os.path.join(os.path.pardir,\"data\",\"processed\")\n",
    "pr_train_path=os.path.join(processed_dir,\"train.csv\")\n",
    "pr_test_path=os.path.join(processed_dir,\"test.csv\")\n",
    "train_df = pd.read_csv(pr_train_path,index_col=\"PassengerId\")\n",
    "test_df = pd.read_csv(pr_test_path,index_col=\"PassengerId\")\n",
    "# train_df.info()\n",
    "# test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(891, 32) (891,)\n"
     ]
    }
   ],
   "source": [
    "X = train_df.loc[:,\"Age\":].as_matrix().astype(\"float\")\n",
    "y = train_df[\"Survived\"].ravel()\n",
    "print(type(X),type(y))\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 32) (712,) (179, 32) (179,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print(Xtrain.shape, ytrain.shape, Xtest.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean survival in train set : 0.383\n",
      "mean survival in test set : 0.385\n"
     ]
    }
   ],
   "source": [
    "print(\"mean survival in train set : {0:.3f}\".format(np.mean(ytrain)))\n",
    "print(\"mean survival in test set : {0:.3f}\".format(np.mean(ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for baseline model : 0.61\n",
      "Accuracy of our baseline model : 0.61\n",
      "Confusion Matrix of our baseline model : \n",
      "[[110   0]\n",
      " [ 69   0]]\n",
      "Precision Score of our baseline model : 0.00\n",
      "Recall Score of our baseline model : 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\debab\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__\n",
    "# '0.19.0'\n",
    "from sklearn.dummy import DummyClassifier as dc\n",
    "model_dummy = dc(strategy=\"most_frequent\", random_state=25)\n",
    "model_dummy.fit(Xtrain, ytrain)\n",
    "print(\"Score for baseline model : {0:.2f}\".format(model_dummy.score(Xtest,ytest)))\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "print(\"Accuracy of our baseline model : {0:.2f}\".format(accuracy_score(ytest, model_dummy.predict(Xtest))))\n",
    "print(\"Confusion Matrix of our baseline model : \\n{0}\".format(confusion_matrix(ytest, model_dummy.predict(Xtest))))\n",
    "print(\"Precision Score of our baseline model : {0:.2f}\".format(precision_score(ytest, model_dummy.predict(Xtest))))\n",
    "print(\"Recall Score of our baseline model : {0:.2f}\".format(recall_score(ytest, model_dummy.predict(Xtest))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = test_df.as_matrix().astype(\"float\")\n",
    "pred = model_dummy.predict(testX)\n",
    "df_submit = pd.DataFrame({\"PassengerId\":test_df.index,\"Survived\":pred})\n",
    "df_submit.head()\n",
    "import pathlib2 as pl2\n",
    "submit_data_path = os.path.join(os.path.pardir,'data','external')\n",
    "pl2.Path(submit_data_path).mkdir(parents=True, exist_ok=True)\n",
    "sub_fl_path = os.path.join(submit_data_path,\"baseline_pred.csv\")\n",
    "df_submit.to_csv(sub_fl_path,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_submission_file(model, filename):\n",
    "    testX = test_df.as_matrix().astype(\"float\")\n",
    "    pred = model.predict(testX)\n",
    "    df_submit = pd.DataFrame({\"PassengerId\":test_df.index,\"Survived\":pred})\n",
    "    df_submit.head()\n",
    "    import pathlib2 as pl2\n",
    "    submit_data_path = os.path.join(os.path.pardir,'data','external')\n",
    "    pl2.Path(submit_data_path).mkdir(parents=True, exist_ok=True)\n",
    "    sub_fl_path = os.path.join(submit_data_path,filename)\n",
    "    df_submit.to_csv(sub_fl_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_submission_file(model_dummy,\"baseline_pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of logistic regression - version 1 : 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "mdl_lr_1 = lr()\n",
    "mdl_lr_1.fit(Xtrain, ytrain)\n",
    "print(\"Score of logistic regression - version 1 : {0:.2f}\".format(mdl_lr_1.score(Xtest,ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_metrics(Xtest, ytest, model):\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "    print(\"Accuracy of our baseline model : {0:.2f}\".format(accuracy_score(ytest, model.predict(Xtest))))\n",
    "    print(\"Confusion Matrix of our baseline model : \\n{0}\".format(confusion_matrix(ytest, model.predict(Xtest))))\n",
    "    print(\"Precision Score of our baseline model : {0:.2f}\".format(precision_score(ytest, model.predict(Xtest))))\n",
    "    print(\"Recall Score of our baseline model : {0:.2f}\".format(recall_score(ytest, model.predict(Xtest))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our baseline model : 0.83\n",
      "Confusion Matrix of our baseline model : \n",
      "[[95 15]\n",
      " [15 54]]\n",
      "Precision Score of our baseline model : 0.78\n",
      "Recall Score of our baseline model : 0.78\n"
     ]
    }
   ],
   "source": [
    "get_metrics(Xtest, ytest, mdl_lr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02840734,  0.00455631, -0.50017004,  0.61922838, -0.81414743,\n",
       "         0.12823264, -0.17253859, -0.39355488,  0.52215008,  1.09939125,\n",
       "         0.40346551, -0.18369316, -0.30021028,  0.96558544,  0.48281794,\n",
       "        -0.3451608 ,  0.28258585,  1.21850069,  0.56334183, -1.44612507,\n",
       "         1.07146232, -0.11345497, -0.47306807,  0.16297326,  0.24746349,\n",
       "         0.27998252,  0.4128233 ,  0.49202884,  0.46214499,  0.14906873,\n",
       "         0.37253571,  0.73070686]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_lr_1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_submission_file(mdl_lr_1,\"lr_1_pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl_lr_2 = lr(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'penalty': 'l1'}\n",
      "Best Score : 0.83\n",
      "Score of logistic regression - version 2 : 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV as gsv\n",
    "param = {\"C\":[1.0,5.0,10.0,50.0,100.0,500.0,1000.0,5000.0],\"penalty\":[\"l1\",\"l2\"],}\n",
    "clf=gsv(mdl_lr_2, param_grid=param, cv=3)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "from pprint import pprint as pp\n",
    "pp(clf.best_params_)\n",
    "print(\"Best Score : {0:.2f}\".format(clf.best_score_))\n",
    "print(\"Score of logistic regression - version 2 : {0:.2f}\".format(clf.score(Xtest, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_submission_file(clf,\"lr_2_pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "Xtrain_sc = scaler.fit_transform(Xtrain)\n",
    "print(Xtrain_sc[:,0].min(),Xtrain_sc[:,0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtest_sc = scaler.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.14395510183 3.80311270129\n",
      "{'C': 1.0, 'penalty': 'l1'}\n",
      "Best Score : 0.82\n",
      "Score of logistic regression - version 3 : 0.84\n"
     ]
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "Xtrain_stdsc = std_scaler.fit_transform(Xtrain)\n",
    "print(Xtrain_stdsc[:,0].min(),Xtrain_stdsc[:,0].max())\n",
    "Xtest_stdsc = std_scaler.transform(Xtest)\n",
    "clf1=gsv(mdl_lr_2, param_grid=param, cv=5)\n",
    "clf1.fit(Xtrain_stdsc, ytrain)\n",
    "from pprint import pprint as pp\n",
    "pp(clf1.best_params_)\n",
    "print(\"Best Score : {0:.2f}\".format(clf1.best_score_))\n",
    "print(\"Score of logistic regression - version 3 : {0:.2f}\".format(clf1.score(Xtest_stdsc, ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'C': [1.0, 5.0, 10.0, 50.0, 100.0, 500.0, 1000.0, 5000.0], 'penalty': ['l1', 'l2']},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0) StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "Score for persisted logistic regression : 0.84\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "model_file_path = os.path.join(os.path.pardir, 'models', 'lr_model.pkl')\n",
    "scalar_file_path = os.path.join(os.path.pardir, 'models', 'lr_scalar.pkl')\n",
    "mdl_fl_pkl = open(model_file_path,\"wb\")\n",
    "scl_fl_pkl = open(scalar_file_path,\"wb\")\n",
    "pickle.dump(clf1, mdl_fl_pkl)\n",
    "pickle.dump(std_scaler, scl_fl_pkl)\n",
    "mdl_fl_pkl.close()\n",
    "scl_fl_pkl.close()\n",
    "\n",
    "mdl_fl_pkl = open(model_file_path,\"rb\")\n",
    "scl_fl_pkl = open(scalar_file_path,\"rb\")\n",
    "\n",
    "clf_loaded = pickle.load(mdl_fl_pkl)\n",
    "scl_loaded = pickle.load(scl_fl_pkl)\n",
    "\n",
    "print(clf_loaded, scl_loaded)\n",
    "X_test_scaled = scl_loaded.transform(Xtest)\n",
    "print(\"Score for persisted logistic regression : {0:.2f}\".format(clf_loaded.score(X_test_scaled,ytest)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
